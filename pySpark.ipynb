{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShachiniMekala/Google_PlayStore_Analysis/blob/main/pySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7X-8-qaHwu4"
      },
      "source": [
        "# Background Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1fRFZTdb-ZQ",
        "outputId": "ac56211c-6c26-4014-d164-7b82f46857c1"
      },
      "source": [
        "!apt install python3-wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-asn1crypto python-cffi-backend python-cryptography python-enum34\n",
            "  python-idna python-ipaddress python-openssl python-six python-urllib3\n",
            "Suggested packages:\n",
            "  python-cryptography-doc python-cryptography-vectors python-enum34-doc\n",
            "  python-openssl-doc python-openssl-dbg python-ntlm python-socks\n",
            "The following NEW packages will be installed:\n",
            "  python-asn1crypto python-cffi-backend python-cryptography python-enum34\n",
            "  python-idna python-ipaddress python-openssl python-six python-urllib3\n",
            "  python3-wget\n",
            "0 upgraded, 10 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 647 kB of archives.\n",
            "After this operation, 3,808 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-openssl all 17.5.0-1ubuntu1 [41.3 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-urllib3 all 1.22-1ubuntu0.18.04.2 [86.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wget all 3.2-1 [11.3 kB]\n",
            "Fetched 647 kB in 1s (496 kB/s)\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../1-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../2-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../3-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../4-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../5-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../6-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-openssl.\n",
            "Preparing to unpack .../7-python-openssl_17.5.0-1ubuntu1_all.deb ...\n",
            "Unpacking python-openssl (17.5.0-1ubuntu1) ...\n",
            "Selecting previously unselected package python-urllib3.\n",
            "Preparing to unpack .../8-python-urllib3_1.22-1ubuntu0.18.04.2_all.deb ...\n",
            "Unpacking python-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package python3-wget.\n",
            "Preparing to unpack .../9-python3-wget_3.2-1_all.deb ...\n",
            "Unpacking python3-wget (3.2-1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python3-wget (3.2-1) ...\n",
            "Setting up python-openssl (17.5.0-1ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JJp7wCGb9uI"
      },
      "source": [
        "import wget\n",
        "def bar_custom(current, total, width=80):\n",
        "    print_str=(\"\\r\\rDownloading: %d%% [%dM / %dM] bytes\" % (current / total * 100, current/(1024*1024), total/(1024*1024)))\n",
        "    print (len(print_str)*'\\b',print_str, end =\"\")\n",
        "#Now use this like below,\n",
        "url = 'https://storage.googleapis.com/kaggle-data-sets/157336/1712743/compressed/Google-Playstore.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210516%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210516T172807Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4e56e6e297627b969ceec99c8f39b0b3d2aaeb16b0944f073656904bbdaf826d29c896fdc82537549d1bf91a524370a2d078b4cda34c69afa755f6966e1b46112c5aa0c7172d6691836f0b26688713b223c81d0026fe04a923037d07499aeeb8d407790b95c92b8050603a30b0677ba0754ab5dbcb9d2b06b119f007d0433558170507e5013438fe8081927b1efbd8a073ef31e81de71276570a7869717fc7b3dbc73042846458ecf2e9d94c5fa5b26fbf71bf11880ffb61192df3747146d20ca800cf06386a0c563a3b96243e047a5aac17b12cf2709b712027ed31d8424057f0063bc3bb3c60f0de710a3bd78a13d8f66d8776de333255f25d58d496d26d69'\n",
        "save_path = \"/content/\"\n",
        "wget.download(url, save_path, bar=bar_custom)\n",
        "\n",
        "print('\\nfinished...!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDr5p0JT9mo"
      },
      "source": [
        "!unzip \"/content/Google-Playstore.csv.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ACRtYlMUDKS"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkgvH9OVUFD9"
      },
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPNluTmdUzhZ"
      },
      "source": [
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK__0psSVBOo"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFDYNt1mVVFZ"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roni5EHvV8Mg"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcoxfyR3XWmA"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1t1id8mXbqv"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import isnan, when, count, col, regexp_replace, lit, round, length, trim, concat, to_date\n",
        "from pyspark.sql.types import StringType, BooleanType, IntegerType, FloatType, DecimalType, DateType, DoubleType, LongType\n",
        "from pyspark.ml.feature import Imputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAl0UlpOXjp_"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Data Preprocessing\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdYmQDGZXmTv"
      },
      "source": [
        "dataset = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true', quote='\"',\n",
        "                                                                delimiter=',').load('/content/Google-Playstore.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndnkKvamAMNi"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oms6fcJSYibp"
      },
      "source": [
        "# Drop duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSOqI3ZJYkGf"
      },
      "source": [
        "print('\\nOriginal count: ', dataset.count())\n",
        "dataset = dataset.dropDuplicates()\n",
        "print('\\nAfter removing duplicate values: ', dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFrQBX9JYsJe"
      },
      "source": [
        "# Drop unwanted columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ5IUH2iTt5Z"
      },
      "source": [
        "dataset = dataset.drop('Installs', 'Minimum Installs', 'Price', 'Currency', 'Developer Website',\n",
        "                       'Developer Email', 'Privacy Policy', 'Editors Choice')\n",
        "dataset.show()\n",
        "print('Unwanted columns dropped')\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lft-umDwYSBv"
      },
      "source": [
        "# Drop Null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaXzA3uyYGMw"
      },
      "source": [
        "dataset = dataset.na.drop(how='any', subset=['Category', 'Developer Id', 'Ad Supported', 'In App Purchases'])\n",
        "dataset.show()\n",
        "print('Null values dropped')\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeWU9-1mHjpP"
      },
      "source": [
        "# Get null count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlVtp0xEHmh3"
      },
      "source": [
        "dataset.select([count(when(col(c).isNull(), c)).alias(c) for c in dataset.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZogKiYSDIDL"
      },
      "source": [
        "# Data Cleaning for \"Free\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-v2VhFDOhh"
      },
      "source": [
        "dataset = dataset.filter(\n",
        "    dataset['Free'].contains('True') |\n",
        "    dataset['Free'].contains('False')\n",
        ")\n",
        "dataset.show()\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAlhJhQmJgxN"
      },
      "source": [
        "# Data cleaning for \"Category\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHNb7WNvJgSO"
      },
      "source": [
        "dataset = dataset.filter(\n",
        "    dataset.Category.contains('Communication') |\n",
        "    dataset.Category.contains('Strategy') |\n",
        "    dataset.Category.contains('Tools') |\n",
        "    dataset.Category.contains('Music & Audio') |\n",
        "    dataset.Category.contains('Maps & Navigation') |\n",
        "    dataset.Category.contains('Lifestyle') |\n",
        "    dataset.Category.contains('Educational') |\n",
        "    dataset.Category.contains('Education') |\n",
        "    dataset.Category.contains('Productivity') |\n",
        "    dataset.Category.contains('Business') |\n",
        "    dataset.Category.contains('Board') |\n",
        "    dataset.Category.contains('Sports') |\n",
        "    dataset.Category.contains('Medical') |\n",
        "    dataset.Category.contains('Finance') |\n",
        "    dataset.Category.contains('Parenting') |\n",
        "    dataset.Category.contains('Puzzle') |\n",
        "    dataset.Category.contains('Casual') |\n",
        "    dataset.Category.contains('Events') |\n",
        "    dataset.Category.contains('Music') |\n",
        "    dataset.Category.contains('Trivia') |\n",
        "    dataset.Category.contains('Arcade') |\n",
        "    dataset.Category.contains('Personalization') |\n",
        "    dataset.Category.contains('Entertainment') |\n",
        "    dataset.Category.contains('Action') |\n",
        "    dataset.Category.contains('Travel & Local') |\n",
        "    dataset.Category.contains('Auto & Vehicles') |\n",
        "    dataset.Category.contains('Health & Fitness') |\n",
        "    dataset.Category.contains('House & Home') |\n",
        "    dataset.Category.contains('News & Magazines') |\n",
        "    dataset.Category.contains('Food & Drink') |\n",
        "    dataset.Category.contains('Books & Reference') |\n",
        "    dataset.Category.contains('Shopping') |\n",
        "    dataset.Category.contains('Simulation') |\n",
        "    dataset.Category.contains('Racing') |\n",
        "    dataset.Category.contains('Weather') |\n",
        "    dataset.Category.contains('Adventure') |\n",
        "    dataset.Category.contains('Social') |\n",
        "    dataset.Category.contains('Word') |\n",
        "    dataset.Category.contains('Comics') |\n",
        "    dataset.Category.contains('Card') |\n",
        "    dataset.Category.contains('Casino') |\n",
        "    dataset.Category.contains('Beauty') |\n",
        "    dataset.Category.contains('Dating') |\n",
        "    dataset.Category.contains('Libraries & Demo') |\n",
        "    dataset.Category.contains('Video Players & Editors') |\n",
        "    dataset.Category.contains('Art & Design') |\n",
        "    dataset.Category.contains('Role Playing') |\n",
        "    dataset.Category.contains('Photography')\n",
        ")\n",
        "dataset.show()\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OxCQI1HQa-X"
      },
      "source": [
        "# Data cleaning for \"Content Rating\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNS1mL5fQgak"
      },
      "source": [
        "dataset = dataset.filter(\n",
        "    dataset['Content Rating'].contains('Everyone') |\n",
        "    dataset['Content Rating'].contains('Teen') |\n",
        "    dataset['Content Rating'].contains('Adults only 18+') |\n",
        "    dataset['Content Rating'].contains('Mature 17+') |\n",
        "    dataset['Content Rating'].contains('Everyone 10+') \n",
        ")\n",
        "dataset.show()\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWcqCagLYMH3"
      },
      "source": [
        "# Data cleaning for \"Size\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_gtSnnsYKyH"
      },
      "source": [
        "dataset = dataset.filter(\n",
        "    dataset.Size.contains('M') |\n",
        "    dataset.Size.contains('G') |\n",
        "    dataset.Size.contains('k') |\n",
        "    dataset.Size.contains('Varies with device') \n",
        ")\n",
        "dataset = dataset.withColumn('Size', regexp_replace(col('Size'), r'(M)', ''))\n",
        "dataset = dataset.withColumn('Size',\n",
        "                             when(\n",
        "                                 dataset.Size.contains('G'),\n",
        "                                 round(regexp_replace(col('Size'), r'(G)', '').cast('float') * 1024, 2)\n",
        "                             ).\n",
        "                             otherwise(col('Size')))\n",
        "dataset = dataset.withColumn('Size',\n",
        "                             when(\n",
        "                                 dataset.Size.contains('k'),\n",
        "                                 round(regexp_replace(col('Size'), r'(k)', '').cast('float') / 1024, 2)\n",
        "                             ).\n",
        "                             otherwise(col('Size')))\n",
        "dataset = dataset.withColumn('Size',\n",
        "                             when(\n",
        "                                 dataset.Size.contains('Varies'),\n",
        "                                 lit(None)\n",
        "                                 # np.nan\n",
        "                             ).\n",
        "                             otherwise(col('Size')))\n",
        "dataset = dataset.withColumn('Size', col(\"Size\").cast(FloatType()))\n",
        "dataset = Imputer(\n",
        "    inputCol='Size',\n",
        "    outputCol='Size'\n",
        ").setStrategy(\"mean\").fit(dataset).transform(dataset).withColumn('Size', round(col('Size'), 2))\n",
        "dataset.show()\n",
        "dd = dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72EC6x-HP6I"
      },
      "source": [
        "# Data cleaning for \"Released\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKSum_r3HJ3h"
      },
      "source": [
        "dataset = dd.withColumn('Released', when(col('Released').isNull(), col('Last Updated')).otherwise(col('Released')))\n",
        "dataset = dataset.filter(\n",
        "    dataset['Released'].contains('Feb') |\n",
        "    dataset['Released'].contains('Mar') |\n",
        "    dataset['Released'].contains('Apr') |\n",
        "    dataset['Released'].contains('Jan') |\n",
        "    dataset['Released'].contains('May') |\n",
        "    dataset['Released'].contains('Jun') |\n",
        "    dataset['Released'].contains('Jul') |\n",
        "    dataset['Released'].contains('Aug') |\n",
        "    dataset['Released'].contains('Sep') |\n",
        "    dataset['Released'].contains('Oct') |\n",
        "    dataset['Released'].contains('Nov') |\n",
        "    dataset['Released'].contains('Dec')\n",
        ")\n",
        "dataset = dataset.withColumn('month', trim(col('Released')).substr(1,3))\n",
        "dataset = dataset.withColumn('date', trim(col('Released')).substr(5,2))\n",
        "dataset = dataset.withColumn('year', trim(col('Released')).substr(9,4))\n",
        "dataset = dataset.filter((dataset.date >= 1) & (dataset.date <= 31))\n",
        "dataset = dataset.filter((dataset.year >= 2000) & (dataset.year <= 2021))\n",
        "dataset = dataset.filter(dataset.month.rlike('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)'))\n",
        "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "for m in months:\n",
        "  dataset = dataset.withColumn('month',\n",
        "                               when(\n",
        "                                   dataset['Released'].contains(m),\n",
        "                                    lit(months.index(m)+1)\n",
        "                                    ).otherwise(col('month')))                               \n",
        "dataset = dataset.withColumn('Released',concat(dataset.year,lit('-'),dataset.month,lit('-'),dataset.date))\n",
        "dataset = dataset.withColumn('Released', col('Released').cast(DateType()))\n",
        "dataset = dataset.drop('month','year','date')\n",
        "dataset.show()\n",
        "print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXc-Yv4MY-Ni"
      },
      "source": [
        "# Data cleaning for \"Last Updated\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTHC5QUZEr4"
      },
      "source": [
        "dataset = dataset.filter(\n",
        "    dataset['Last Updated'].contains('Jan') |\n",
        "    dataset['Last Updated'].contains('Feb') |\n",
        "    dataset['Last Updated'].contains('Mar') |\n",
        "    dataset['Last Updated'].contains('Apr') |\n",
        "    dataset['Last Updated'].contains('May') |\n",
        "    dataset['Last Updated'].contains('Jun') |\n",
        "    dataset['Last Updated'].contains('Jul') |\n",
        "    dataset['Last Updated'].contains('Aug') |\n",
        "    dataset['Last Updated'].contains('Sep') |\n",
        "    dataset['Last Updated'].contains('Oct') |\n",
        "    dataset['Last Updated'].contains('Nov') |\n",
        "    dataset['Last Updated'].contains('Dec')\n",
        ")\n",
        "dataset = dataset.withColumn('month', trim(col('Last Updated')).substr(1,3))\n",
        "dataset = dataset.withColumn('date', trim(col('Last Updated')).substr(5,2))\n",
        "dataset = dataset.withColumn('year', trim(col('Last Updated')).substr(9,4))\n",
        "dataset = dataset.filter((dataset.date >= 1) & (dataset.date <= 31))\n",
        "dataset = dataset.filter((dataset.year >= 2000) & (dataset.year <= 2021))\n",
        "dataset = dataset.filter(dataset.month.rlike('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)'))\n",
        "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "for m in months:\n",
        "  dataset = dataset.withColumn('month',\n",
        "                               when(\n",
        "                                   dataset['Last Updated'].contains(m),\n",
        "                                    lit(months.index(m)+1)\n",
        "                                    ).otherwise(col('month')))                   \n",
        "dataset = dataset.withColumn('Last Updated',concat(dataset.year,lit('-'),dataset.month,lit('-'),dataset.date))\n",
        "dataset = dataset.withColumn('Last Updated', col('Last Updated').cast(DateType()))\n",
        "dataset = dataset.drop('month','year','date')\n",
        "dataset.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQBaZIlR7VgL"
      },
      "source": [
        "# Data cleaning for 'Minimum Android' column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD_e6lRa7koC"
      },
      "source": [
        "dataset = dataset.withColumn('Minimum Android',\n",
        "                             when(\n",
        "                                 dataset['Minimum Android'].contains('Varies'),\n",
        "                                 lit(None)\n",
        "                             ).\n",
        "                             otherwise(col('Minimum Android')))\n",
        "dataset = dataset.withColumn('Minimum Android',\n",
        "                             when(\n",
        "                                 dataset['Minimum Android'].contains('and up'),\n",
        "                                 trim(regexp_replace(col('Minimum Android'), r'(and up)', ''))\n",
        "                             ).\n",
        "                             otherwise(col('Minimum Android')))\n",
        "dataset = dataset.withColumn('Minimum Android',\n",
        "                             when(\n",
        "                                 length(trim(dataset['Minimum Android']))>3,\n",
        "                                 trim(dataset['Minimum Android'].substr(1,3))\n",
        "                             ).\n",
        "                             otherwise(col('Minimum Android')))\n",
        "dataset = dataset.withColumn('Minimum Android',col('Minimum Android').cast(FloatType()))\n",
        "\n",
        "dataset = Imputer(\n",
        "    inputCol='Minimum Android',\n",
        "    outputCol='Minimum Android'\n",
        ").setStrategy(\"mode\").fit(dataset).transform(dataset)\n",
        "dataset = dataset.filter((dataset['Minimum Android'] > 1.0) & (dataset['Minimum Android'] < 10.0))\n",
        "dataset.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWb6NIXJydHC"
      },
      "source": [
        "# Cast data types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWBcq8vCxct6"
      },
      "source": [
        "dataset = dataset.withColumn('Ad Supported', col('Ad Supported').cast(BooleanType())) \\\n",
        "    .withColumn('In App Purchases', col('In App Purchases').cast(BooleanType())) \\\n",
        "    .withColumn('Maximum Installs', col('Maximum Installs').cast(LongType())) \\\n",
        "    .withColumn('Rating', col('Rating').cast(FloatType())) \\\n",
        "    .withColumn('Rating Count', col('Rating Count').cast(IntegerType()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj63nEYGQW4c"
      },
      "source": [
        "# Drop Rating null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Q6LbfoQcAb"
      },
      "source": [
        "#dataset = dataset.filter(dataset.Rating.isNotNull())\n",
        "#dataset.show()\n",
        "#print(dataset.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rupjBW3DY_z6"
      },
      "source": [
        "# Get null count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThdKRj-bZEff"
      },
      "source": [
        "dataset.select([count(when(col(c).isNull(), c)).alias(c) for c in dataset.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KRZE3M9wk-6"
      },
      "source": [
        "dataset.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxw1nPJrJz8S"
      },
      "source": [
        "# Data cleaning for \"Rating\" and \"Rating Count\" columns "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iRV_6mUKCbz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#converts pyspark dataframe into pandas\n",
        "df = dataset.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tZqGGwROlap"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Splitting data into equi width bins according to the values in 'Maximum Installs' column\n",
        "labels = ['Very Low','Low', 'Average', 'High', 'Very High']\n",
        "\n",
        "min_value = df['Maximum Installs'].min()\n",
        "max_value = df['Maximum Installs'].max()\n",
        "\n",
        "bins = np.linspace(min_value,max_value,6)\n",
        "\n",
        "#insert a new column according to the bin\n",
        "df['Install State'] = pd.cut(df['Maximum Installs'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2dkzWmOtGF"
      },
      "source": [
        "#calculating mean for each bin\n",
        "result_rating_mean = df.groupby('Install State').agg({'Rating': ['mean']})\n",
        "result_rating_mean.columns = result_rating_mean.columns.droplevel(0)\n",
        "\n",
        "#assign mean in each bin into variables\n",
        "rating_very_low=result_rating_mean['mean'].values[0]\n",
        "rating_low=result_rating_mean['mean'].values[1]\n",
        "rating_average=result_rating_mean['mean'].values[2]\n",
        "rating_high=result_rating_mean['mean'].values[3]\n",
        "rating_very_high=result_rating_mean['mean'].values[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsKlftf7P4gS"
      },
      "source": [
        "#dataset.describe(['Maximum Installs']).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0m2lfP1Oy8D"
      },
      "source": [
        "#calculating mean for each bin\n",
        "result_rating_count_mean=df.groupby('Install State').agg({'Rating Count': ['mean']})\n",
        "result_rating_count_mean.columns = result_rating_count_mean.columns.droplevel(0)\n",
        "\n",
        "#assign mean in each bin into variables\n",
        "rcount_very_low=result_rating_count_mean['mean'].values[0]\n",
        "rcount_low=result_rating_count_mean['mean'].values[1]\n",
        "rcount_average=result_rating_count_mean['mean'].values[2]\n",
        "rcount_high=result_rating_count_mean['mean'].values[3]\n",
        "rcount_very_high=result_rating_count_mean['mean'].values[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6NijqOnWIH-"
      },
      "source": [
        "#take null values count before replacing\n",
        "nan_rating=df['Rating'].isna().sum() #null count\n",
        "print(\"Before Replacing - 'Rating' Null Values Count \")\n",
        "print(nan_rating)\n",
        "\n",
        "nan_rating_count=df['Rating Count'].isna().sum() #null count\n",
        "print(\"Before Replacing - 'Rating Count' Null Values Count \")\n",
        "print(nan_rating_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-BZWq_LUdIz"
      },
      "source": [
        "#for Ratings\n",
        "df['Rating'] = df.apply(lambda row: rating_very_low if pd.isnull(row['Rating']) and row['Install State']=='Very Low' \\\n",
        "                        else rating_low if pd.isnull(row['Rating']) and row['Install State']=='Low' \\\n",
        "                        else rating_average if pd.isnull(row['Rating']) and row['Install State']=='Average' \\\n",
        "                        else rating_high if pd.isnull(row['Rating']) and row['Install State']=='High' \\\n",
        "                        else rating_very_high if pd.isnull(row['Rating']) and row['Install State']=='Very High' \\\n",
        "                        else row['Rating'], axis=1)\n",
        "\n",
        "#for rating count\n",
        "df['Rating Count'] = df.apply(lambda row: rcount_very_low if pd.isnull(row['Rating Count']) and row['Install State']=='Very Low' \\\n",
        "                              else rcount_low if pd.isnull(row['Rating Count']) and row['Install State']=='Low' \\\n",
        "                              else rcount_average if pd.isnull(row['Rating Count']) and row['Install State']=='Average' \\\n",
        "                              else rcount_high if pd.isnull(row['Rating Count']) and row['Install State']=='High' \\\n",
        "                              else rcount_very_high if pd.isnull(row['Rating Count']) and row['Install State']=='Very High' \\\n",
        "                              else row['Rating Count'], axis=1)\n",
        "\n",
        "#rounding values\n",
        "df['Rating']=np.round(df['Rating'], decimals=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTiZCQ6_pYQF"
      },
      "source": [
        "#take null values count after replacing\n",
        "nan_rating=df['Rating'].isna().sum() #null count\n",
        "print(\"After Replacing - 'Rating' Null Values Count \")\n",
        "print(nan_rating)\n",
        "\n",
        "nan_rating_count=df['Rating Count'].isna().sum() #null count\n",
        "print(\"After Replacing - 'Rating Count' Null Values Count \")\n",
        "print(nan_rating_count)\n",
        "\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi7pbFktvj5s"
      },
      "source": [
        "# Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfIKpZHnB1HZ"
      },
      "source": [
        "**Negative correlation :**\n",
        "The y values tend to decrease as the x values increase. This shows strong negative correlation, which occurs when large values of one feature correspond to small values of the other, and vice versa.\n",
        "\n",
        "**Weak or no correlation** **:** \n",
        "Occurs when an association between two features is not obvious or is hardly observable.\n",
        "\n",
        "**Positive correlation** **:** \n",
        "Strong positive correlation, which occurs when large values of one feature correspond to large values of the other, and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHkzbtvsvoYT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzOvGeFZAb7H"
      },
      "source": [
        "#correlation matrix\n",
        "df_numerical=df[['Rating','Rating Count','Maximum Installs','Size','Minimum Android']]\n",
        "df_numerical.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec8Rvdq5vwUg"
      },
      "source": [
        "x=np.array(df['Rating Count'].tolist())\n",
        "y=np.array(df['Maximum Installs'].tolist())\n",
        "\n",
        "# x=np.array(df['Rating'].tolist())\n",
        "# y=np.array(df['Maximum Installs'].tolist())\n",
        "\n",
        "# x=np.array(df['Rating'].tolist())\n",
        "# y=np.array(df['Size'].tolist())\n",
        "\n",
        "r = np.corrcoef(x, y)\n",
        "\n",
        "slope, intercept, r, p, stderr = scipy.stats.linregress(x, y)\n",
        "\n",
        "line = f'Regression line: y={intercept:.2f}+{slope:.2f}x, r={r:.2f}'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y, linewidth=0, marker='s', label='Data points')\n",
        "ax.plot(x, intercept + slope * x, label=line)\n",
        "ax.set_xlabel('Rating Count')\n",
        "ax.set_ylabel('Installs')\n",
        "ax.legend(facecolor='white')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzzZlOfvwcaS"
      },
      "source": [
        "######################################### Do not Run ###################################################333\n",
        "#rounding off values\n",
        "df['Rating']=df['Rating'].round(decimals=1)\n",
        "# df['Rating']=df['Rating Count'].round(decimals=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyU3SY3yB1-K"
      },
      "source": [
        "# Finalizing the cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MGxIGn3_2xP"
      },
      "source": [
        "#count the null count in each column\n",
        "null_count=df.isnull().sum()\n",
        "null_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJh9nu8vBz_f"
      },
      "source": [
        "#Export the Cleanes Datased into a .CSV\n",
        "df.to_csv(r'/content/Google-Playstore-Cleaned.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmLLJeoaHoxd"
      },
      "source": [
        "# Data Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A4OFW7VKuIj"
      },
      "source": [
        "# Identify the most rated category in Google play store"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9ZbLctwKsIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "415a32c6-bbcf-4e2e-cd7e-9d6cb57e01de"
      },
      "source": [
        "category_wise_mean=df.groupby('Category').agg({'Rating': ['mean']})\n",
        "category_wise_mean=category_wise_mean.columns.droplevel(0)\n",
        "\n",
        "category_wise_mean_df = pd.DataFrame(category_wise_mean)\n",
        "category_wise_mean_df\n",
        "#print(category_wise_mean[category_wise_mean['mean'] == category_wise_mean['mean'].max()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0\n",
              "0  mean"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}